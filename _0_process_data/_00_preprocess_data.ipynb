{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aaedc888-3b79-4eec-ad8d-fb946a697e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc0aad-0f50-429f-99cd-2d23bb9b7b91",
   "metadata": {},
   "source": [
    "**Data Preprocessing in ML**\n",
    "\n",
    "    1. Remove NA values\n",
    "    2. Remove outliers\n",
    "    3. Rescale column by column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ec96a-8b7d-46fe-8a89-6db5b9ca64a2",
   "metadata": {},
   "source": [
    "project_dir = \"/home/jupyter-tfg2425paula/prediction_project_v2\"\n",
    "os.chdir(project_dir)\n",
    "data_dir = os.path.join(project_dir, \"raw_data\")\n",
    "stocks_folder = os.path.join(data_dir, \"single_names\")\n",
    "stock = 'EQNR'\n",
    "filename = f'{stock}_Close.csv'\n",
    "\n",
    "df = pd.read_csv(os.path.join(stocks_folder, filename), sep=\";\", decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369023c6-2fb3-4f1d-92cc-d65bda6ae4da",
   "metadata": {
    "tags": []
   },
   "source": [
    "project_dir = \"/home/jupyter-tfg2425paula/prediction_project_v2\"\n",
    "functions_dir = os.path.join(project_dir, \"arima_garch/functions\")\n",
    "sys.path.append(project_dir)\n",
    "python_files = [f for f in os.listdir(functions_dir) if f.endswith(\".py\")]\n",
    "\n",
    "for file in python_files:\n",
    "    module_name = file.replace(\".py\", \"\")\n",
    "    print(f\"Importing module: {module_name}\")\n",
    "    globals()[module_name] = __import__(f\"arima_garch.functions.{module_name}\", fromlist=[\"*\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826377c-3b55-4185-aa3c-ff60154a924a",
   "metadata": {},
   "source": [
    "**0. Deal with Return and Date columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333b1ab-e81d-4288-95d1-bb88272783a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appropiate_date_format(df, date_col_name, date_format=\"%d/%m/%y\"):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    df[date_col_name] = pd.to_datetime(df[date_col_name], format=date_format)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79495958-a422-40e5-9ec2-fdc09f63ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_return_column(df, target_col_name):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[target_col_name] = pd.to_numeric(df[target_col_name], errors=\"coerce\")\n",
    "    df[\"Return\"] = df[target_col_name].pct_change(fill_method=\"pad\") * 100 \n",
    "    df = df.drop(columns = target_col_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd9c57-d577-4f3b-9518-e608dbee13c8",
   "metadata": {},
   "source": [
    "**1. Check for NA values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99fcc5ce-4c55-484a-82eb-b641f38ccd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_na(df, selected_cols):\n",
    "    \"\"\"\n",
    "    Handles missing values in specified columns of a DataFrame using linear interpolation.\n",
    "    Removes rows with missing values if they are at the beginning or end.\n",
    "    \"\"\"\n",
    "    na_method = \"linear\"\n",
    "    \n",
    "    # Remove first and last because they usually cause problems \n",
    "    df = df.iloc[1:].copy()\n",
    "    df = df.iloc[:-1].copy()\n",
    "    \n",
    "    print(\"Missing values in each selected column before handling:\")\n",
    "    print(df[selected_cols].isna().sum())\n",
    "\n",
    "    rows_with_na = df[df[selected_cols].isna().any(axis=1)]\n",
    "    print(\"\\nRows with missing values in the selected columns:\")\n",
    "    print(rows_with_na)\n",
    "\n",
    "    # Interpolate missing values for the selected columns\n",
    "    for col in selected_cols:\n",
    "        df[col] = df[col].interpolate(na_method, limit_direction=\"both\")\n",
    "\n",
    "    print(\"\\nMissing values in each selected column after handling:\")\n",
    "    print(df[selected_cols].isna().sum())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb76c6-3fc7-4cc2-86dd-8dedbf6196fd",
   "metadata": {},
   "source": [
    "**2. Remove outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db4a4c38-f771-477e-ba6f-edcfe2f69296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_iqr(df, output_col):\n",
    "    \"\"\"\n",
    "    Replaces outliers in a DataFrame using the IQR method with interpolated or mean/median values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        selected_col (str): The column to process.\n",
    "        threshold (float): The IQR threshold. Default is 1.5.\n",
    "        method (str): The method to replace outliers (\"interpolate\", \"mean\", \"median\"). Default is \"interpolate\".\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with outliers replaced.\n",
    "    \"\"\"\n",
    "    method=\"linear\"\n",
    "    threshold = 1.5\n",
    "    \n",
    "    col = output_col\n",
    "    Q1 = df[col].quantile(0.25)  # First quartile (25th percentile)\n",
    "    Q3 = df[col].quantile(0.75)  # Third quartile (75th percentile)\n",
    "    IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "    # Define outlier boundaries\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    \n",
    "    extreme_outliers = df.loc[outliers, col]\n",
    "    num_outliers = len(extreme_outliers)\n",
    "    min_outlier = extreme_outliers.min() if not extreme_outliers.empty else None\n",
    "\n",
    "    print(f\"Number of outliers eliminated: {num_outliers}\")\n",
    "    print(f\"Minimum extreme outlier value: {min_outlier}\")\n",
    "    \n",
    "    df.loc[outliers, col] = np.nan\n",
    "    df[col] = df[col].interpolate(method, limit_direction=\"both\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781b60d-423e-4b0d-9ed7-2cf4021d3802",
   "metadata": {},
   "source": [
    "**3. Normalize data column by column**\n",
    "\n",
    "    - StandardScaler: subtracts mean and divides by standard deviation. \n",
    "    - MinMaxScaler: arranges values on a specified scale (0, 1) as default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc32b19-2dda-48a5-9cca-50328134dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "def scale_data(df, selected_scale_cols, scaling_method):\n",
    "    \"\"\"\n",
    "    Scales specified columns in a DataFrame using the specified scaling method.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        selected_cols (list): A list of column names to scale.\n",
    "        scaling_method (str): The scaling method to use (\"standard\" or \"minmax\"). Default is \"standard\".\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with specified columns scaled.\n",
    "    \"\"\"\n",
    "    \n",
    "    if scaling_method is not None:\n",
    "        if scaling_method == \"standard\":\n",
    "            scaler = StandardScaler()\n",
    "        elif scaling_method == \"minmax\":\n",
    "            scaler = MinMaxScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaling method. Choose 'standard' or 'minmax'.\")\n",
    "\n",
    "        # Scale only the selected columns\n",
    "        df_scaled = df.copy()\n",
    "        df_scaled[selected_scale_cols] = scaler.fit_transform(df[selected_scale_cols])\n",
    "    \n",
    "    else:\n",
    "        df_scaled = df\n",
    "        \n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013c54e-f654-4211-908c-c986169e50f6",
   "metadata": {},
   "source": [
    "**Condense all steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02ed4f21-9c42-4229-80a9-fdfc1a9c30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, selected_na_cols, output_col, selected_scale_cols, scaling_method):\n",
    "\n",
    "    processed_df = remove_na(df, selected_na_cols)\n",
    "    processed_df = replace_outliers_iqr(processed_df, output_col)\n",
    "    processed_df = scale_data(df, selected_scale_cols, scaling_method)\n",
    "    \n",
    "    return processed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
