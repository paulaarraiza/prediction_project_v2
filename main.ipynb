{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e1e7d0-628b-436d-a5d4-a48ccc40f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import _0_process_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6275d1e-543d-4d45-b5f4-29513fea4411",
   "metadata": {},
   "source": [
    "**Set directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e1dfc5-8e69-40e8-b735-1d4bc39c0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/home/jupyter-tfg2425paula/prediction_project_v2\"\n",
    "os.chdir(project_dir)\n",
    "\n",
    "raw_data_dir = os.path.join(project_dir, \"_00_data_raw\")\n",
    "transformed_data_dir = os.path.join(project_dir, \"_01_data_transformed\")\n",
    "structured_data_dir = os.path.join(project_dir, \"_02_data_structured\")\n",
    "\n",
    "from _0_process_data._00_preprocess_data import preprocess_data\n",
    "from _0_process_data._00_preprocess_data import appropiate_date_format\n",
    "from _0_process_data._00_preprocess_data import create_return_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c045b2-882f-4fa7-95c5-d8e78805522a",
   "metadata": {},
   "source": [
    "## **1. Data** \n",
    "\n",
    "This part of the code structures the process of data loading. At the moment, standardized for:\n",
    "\n",
    "    - Single names\n",
    "    - Single names with technical indicators\n",
    "    - PCA dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c40428-bdf1-4b0d-a04e-76fb24cfa327",
   "metadata": {},
   "source": [
    "Parameters in this part of the code:\n",
    "\n",
    "    - 0. Data filepath\n",
    "    - 1. Stock(s)\n",
    "    - 2. Type of data (Technical / Economic / Options)\n",
    "    - 3. Start and end date (number of values)\n",
    "    - 4. Scaling method (standard, minmax or none)\n",
    "    - 5. Processing method (PCA or none)\n",
    "    - 6. Window size for generated dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120011b0-3d32-4692-b00b-c076e9caadec",
   "metadata": {},
   "source": [
    "**Set parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b0174a-3757-42a0-9ed2-6857567fd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'SPX'\n",
    "data_type = \"stock_technical_ind\"\n",
    "\n",
    "# standard, minmax or None\n",
    "scaling_method = \"standard\"\n",
    "processing_method = None\n",
    "evaluation_metric = \"rolling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99a69f9-d250-477f-b1b1-66dfa74cdc2f",
   "metadata": {},
   "source": [
    "**Load raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332c6246-a1a1-4c45-8461-b64183a7eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"stock_single_name\":\n",
    "\n",
    "    securities = \"single_names\"\n",
    "    stocks_folder = os.path.join(raw_data_dir, securities)\n",
    "    \n",
    "    filename = f'{stock}_Close.csv'\n",
    "\n",
    "    df = pd.read_csv(os.path.join(stocks_folder, filename), sep=\";\", decimal=\",\")\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e02fadf-34fc-47c3-9c2b-3f7a67dee02c",
   "metadata": {},
   "source": [
    "**If single names: clean, remove outliers and scale loaded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e7e7e8-9e20-4170-9f31-83507a9276cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"stock_single_name\":\n",
    "    clean_stocks_folder = os.path.join(raw_data_dir, 'cleaned_'+ str(securities))\n",
    "\n",
    "    date_col_name = \"Date\"\n",
    "    target_col_name = \"Close\"\n",
    "    return_col = \"Return\"\n",
    "\n",
    "    # standard, minmax or None\n",
    "    scaling_method = \"standard\"\n",
    "\n",
    "    # Only if date_format is not appropiate\n",
    "    df = appropiate_date_format(df, date_col_name, date_format=\"%d/%m/%y\")\n",
    "    df = create_return_column(df, target_col_name, remove_close=True)\n",
    "\n",
    "    selected_na_cols = list(df.columns)\n",
    "    selected_scale_cols = list(df.drop(columns=[date_col_name]).columns) # All but Date\n",
    "\n",
    "    df_clean = preprocess_data(df, selected_na_cols, return_col, selected_scale_cols, scaling_method)\n",
    "    df_clean.to_csv(os.path.join(clean_stocks_folder, filename), index=False)\n",
    "    \n",
    "    start_date = df_clean['Date'].iloc[0]\n",
    "    end_date = df_clean['Date'].iloc[-1]\n",
    "    \n",
    "    df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fee67c-1746-494f-b1f9-d27afb1902e1",
   "metadata": {},
   "source": [
    "**If technical indicator type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea13630e-a657-4633-bbbc-2e6cb6df5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/home/jupyter-tfg2425paula/prediction_project_v2/_0_process_data/_00_preprocess_data.py:53: FutureWarning: The 'fill_method' keyword being not None and the 'limit' keyword in Series.pct_change are deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"Return\"] = df[target_col_name].pct_change(fill_method=\"pad\") * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each selected column before handling:\n",
      "Price\n",
      "Date             0\n",
      "Adj Close        0\n",
      "Close            0\n",
      "High             0\n",
      "Low              0\n",
      "                ..\n",
      "momentum_kama    0\n",
      "others_dr        0\n",
      "others_dlr       0\n",
      "others_cr        0\n",
      "Return           1\n",
      "Length: 94, dtype: int64\n",
      "\n",
      "Rows with missing values in the selected columns:\n",
      "Price       Date  Adj Close    Close     High      Low     Open  Volume  \\\n",
      "122   2010-07-14    0.24983  0.24983  0.24983  0.24983  0.24983    8606   \n",
      "\n",
      "Price     volume_adi  volume_obv  volume_cmf  ...  momentum_ppo_signal  \\\n",
      "122    183255.246712     6360427    0.057912  ...            29.347365   \n",
      "\n",
      "Price  momentum_ppo_hist  momentum_pvo  momentum_pvo_signal  \\\n",
      "122            18.938208    -27.521253            -5.787243   \n",
      "\n",
      "Price  momentum_pvo_hist  momentum_kama  others_dr  others_dlr   others_cr  \\\n",
      "122            -21.73401       0.204269  11.109626   10.534715  384.260507   \n",
      "\n",
      "Price  Return  \n",
      "122       NaN  \n",
      "\n",
      "[1 rows x 94 columns]\n",
      "\n",
      "Missing values in each selected column after handling:\n",
      "Price\n",
      "Date             0\n",
      "Adj Close        0\n",
      "Close            0\n",
      "High             0\n",
      "Low              0\n",
      "                ..\n",
      "momentum_kama    0\n",
      "others_dr        0\n",
      "others_dlr       0\n",
      "others_cr        0\n",
      "Return           0\n",
      "Length: 94, dtype: int64\n",
      "Number of outliers eliminated: 733\n",
      "Minimum extreme outlier value: -91.86287447448424\n"
     ]
    }
   ],
   "source": [
    "if data_type == \"stock_technical_ind\":\n",
    "    \n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-11-01'\n",
    "    \n",
    "    from _0_process_data._01_incorporate_technical_indicators import generate_technical_ind_dataset\n",
    "    technical_ind_folder = os.path.join(transformed_data_dir, 'technical')\n",
    "    filename = 'technical_' + str(stock) + '.csv'\n",
    "    \n",
    "    target_col_name = \"Close\"\n",
    "    date_col_name = \"Date\"\n",
    "    return_col = \"Return\"\n",
    "    \n",
    "    # start and end date in format 2024-11-13, '%Y-%m-%d'\n",
    "    technical_ind_df = generate_technical_ind_dataset(stock, start_date, end_date)\n",
    "    df = create_return_column(technical_ind_df, target_col_name, remove_close=False)\n",
    "    \n",
    "    selected_na_cols = list(df.columns)\n",
    "    selected_scale_cols = list(df.drop(columns=[date_col_name]).columns) # All but Date\n",
    "\n",
    "    df_clean = preprocess_data(df, selected_na_cols, return_col, selected_scale_cols, scaling_method)\n",
    "    df_clean.head()\n",
    "    \n",
    "    df_clean.to_csv(os.path.join(technical_ind_folder, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68b0e370-d2d7-4c00-9cf9-014524058d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "if data_type == \"stock_technical_ind\":\n",
    "    \n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2024-11-01'\n",
    "    \n",
    "    from _0_process_data._01_incorporate_technical_indicators import generate_technical_ind_dataset\n",
    "    technical_ind_folder = os.path.join(transformed_data_dir, 'technical')\n",
    "    filename = 'technical_' + str(stock) + '.csv'\n",
    "    \n",
    "    target_col_name = \"Close\"\n",
    "    date_col_name = \"Date\"\n",
    "    return_col = \"Return\"\n",
    "    \n",
    "    # start and end date in format 2024-11-13, '%Y-%m-%d'\n",
    "    technical_ind_df = generate_technical_ind_dataset(stock, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4861b79-0a07-4ae7-9460-b8631473cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2010-07-14</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>8606</td>\n",
       "      <td>1.832552e+05</td>\n",
       "      <td>6360427</td>\n",
       "      <td>0.057912</td>\n",
       "      <td>...</td>\n",
       "      <td>29.347365</td>\n",
       "      <td>18.938208</td>\n",
       "      <td>-27.521253</td>\n",
       "      <td>-5.787243</td>\n",
       "      <td>-21.734010</td>\n",
       "      <td>0.204269</td>\n",
       "      <td>11.109626</td>\n",
       "      <td>10.534715</td>\n",
       "      <td>384.260507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>3602</td>\n",
       "      <td>1.832552e+05</td>\n",
       "      <td>6364029</td>\n",
       "      <td>0.108695</td>\n",
       "      <td>...</td>\n",
       "      <td>32.858877</td>\n",
       "      <td>14.046049</td>\n",
       "      <td>-33.424322</td>\n",
       "      <td>-11.314658</td>\n",
       "      <td>-22.109663</td>\n",
       "      <td>0.211888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>384.260507</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2010-07-19</td>\n",
       "      <td>0.03714</td>\n",
       "      <td>0.03714</td>\n",
       "      <td>0.03714</td>\n",
       "      <td>0.03714</td>\n",
       "      <td>0.03714</td>\n",
       "      <td>38769</td>\n",
       "      <td>1.832552e+05</td>\n",
       "      <td>6325260</td>\n",
       "      <td>0.065698</td>\n",
       "      <td>...</td>\n",
       "      <td>33.499889</td>\n",
       "      <td>2.564047</td>\n",
       "      <td>-35.154307</td>\n",
       "      <td>-16.082588</td>\n",
       "      <td>-19.071718</td>\n",
       "      <td>0.211124</td>\n",
       "      <td>-85.133890</td>\n",
       "      <td>-190.608608</td>\n",
       "      <td>-28.009302</td>\n",
       "      <td>-85.133890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2010-07-20</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>0.24983</td>\n",
       "      <td>4003</td>\n",
       "      <td>1.832552e+05</td>\n",
       "      <td>6329263</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>...</td>\n",
       "      <td>34.206057</td>\n",
       "      <td>2.824672</td>\n",
       "      <td>-40.290879</td>\n",
       "      <td>-20.924246</td>\n",
       "      <td>-19.366632</td>\n",
       "      <td>0.213051</td>\n",
       "      <td>572.670944</td>\n",
       "      <td>190.608608</td>\n",
       "      <td>384.260507</td>\n",
       "      <td>572.670944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2010-07-21</td>\n",
       "      <td>0.04282</td>\n",
       "      <td>0.04282</td>\n",
       "      <td>0.04282</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>53502</td>\n",
       "      <td>2.367572e+05</td>\n",
       "      <td>6275761</td>\n",
       "      <td>0.189441</td>\n",
       "      <td>...</td>\n",
       "      <td>32.861904</td>\n",
       "      <td>-5.376613</td>\n",
       "      <td>-39.013132</td>\n",
       "      <td>-24.542023</td>\n",
       "      <td>-14.471109</td>\n",
       "      <td>0.212265</td>\n",
       "      <td>-82.860345</td>\n",
       "      <td>-176.377539</td>\n",
       "      <td>-16.999419</td>\n",
       "      <td>-82.860345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>7000</td>\n",
       "      <td>-3.719002e+07</td>\n",
       "      <td>173458527</td>\n",
       "      <td>0.277038</td>\n",
       "      <td>...</td>\n",
       "      <td>9.081971</td>\n",
       "      <td>0.126806</td>\n",
       "      <td>0.741691</td>\n",
       "      <td>7.910342</td>\n",
       "      <td>-7.168651</td>\n",
       "      <td>0.050643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.609809</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>0.05500</td>\n",
       "      <td>1160</td>\n",
       "      <td>-3.719002e+07</td>\n",
       "      <td>173459687</td>\n",
       "      <td>0.276780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000517</td>\n",
       "      <td>-0.325815</td>\n",
       "      <td>-7.771069</td>\n",
       "      <td>4.774060</td>\n",
       "      <td>-12.545129</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.609809</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>1800</td>\n",
       "      <td>-3.719002e+07</td>\n",
       "      <td>173457887</td>\n",
       "      <td>0.315181</td>\n",
       "      <td>...</td>\n",
       "      <td>8.682544</td>\n",
       "      <td>-1.271892</td>\n",
       "      <td>-15.419817</td>\n",
       "      <td>0.735284</td>\n",
       "      <td>-16.155101</td>\n",
       "      <td>0.050823</td>\n",
       "      <td>-9.090907</td>\n",
       "      <td>-9.531016</td>\n",
       "      <td>-3.081990</td>\n",
       "      <td>-9.090907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>60817</td>\n",
       "      <td>-3.725084e+07</td>\n",
       "      <td>173518704</td>\n",
       "      <td>0.249026</td>\n",
       "      <td>...</td>\n",
       "      <td>8.213336</td>\n",
       "      <td>-1.876834</td>\n",
       "      <td>-12.175545</td>\n",
       "      <td>-1.846882</td>\n",
       "      <td>-10.328664</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.081990</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.05000</td>\n",
       "      <td>150100</td>\n",
       "      <td>-3.710074e+07</td>\n",
       "      <td>173668804</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>...</td>\n",
       "      <td>7.655315</td>\n",
       "      <td>-2.232085</td>\n",
       "      <td>2.831380</td>\n",
       "      <td>-0.911229</td>\n",
       "      <td>3.742609</td>\n",
       "      <td>0.050711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.081990</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1894 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date  Adj Close    Close     High      Low     Open  Volume  \\\n",
       "122   2010-07-14    0.24983  0.24983  0.24983  0.24983  0.24983    8606   \n",
       "123   2010-07-15    0.24983  0.24983  0.24983  0.24983  0.24983    3602   \n",
       "124   2010-07-19    0.03714  0.03714  0.03714  0.03714  0.03714   38769   \n",
       "125   2010-07-20    0.24983  0.24983  0.24983  0.24983  0.24983    4003   \n",
       "126   2010-07-21    0.04282  0.04282  0.04282  0.04179  0.04179   53502   \n",
       "...          ...        ...      ...      ...      ...      ...     ...   \n",
       "2011  2018-01-24    0.05500  0.05500  0.05500  0.05500  0.05500    7000   \n",
       "2012  2018-01-25    0.05500  0.05500  0.05500  0.05500  0.05500    1160   \n",
       "2013  2018-01-26    0.05000  0.05000  0.05000  0.05000  0.05000    1800   \n",
       "2014  2018-01-29    0.05000  0.05000  0.06000  0.05000  0.06000   60817   \n",
       "2015  2018-01-30    0.05000  0.05000  0.05000  0.04500  0.05000  150100   \n",
       "\n",
       "Price    volume_adi  volume_obv  volume_cmf  ...  momentum_ppo_signal  \\\n",
       "122    1.832552e+05     6360427    0.057912  ...            29.347365   \n",
       "123    1.832552e+05     6364029    0.108695  ...            32.858877   \n",
       "124    1.832552e+05     6325260    0.065698  ...            33.499889   \n",
       "125    1.832552e+05     6329263    0.065614  ...            34.206057   \n",
       "126    2.367572e+05     6275761    0.189441  ...            32.861904   \n",
       "...             ...         ...         ...  ...                  ...   \n",
       "2011  -3.719002e+07   173458527    0.277038  ...             9.081971   \n",
       "2012  -3.719002e+07   173459687    0.276780  ...             9.000517   \n",
       "2013  -3.719002e+07   173457887    0.315181  ...             8.682544   \n",
       "2014  -3.725084e+07   173518704    0.249026  ...             8.213336   \n",
       "2015  -3.710074e+07   173668804    0.319800  ...             7.655315   \n",
       "\n",
       "Price  momentum_ppo_hist  momentum_pvo  momentum_pvo_signal  \\\n",
       "122            18.938208    -27.521253            -5.787243   \n",
       "123            14.046049    -33.424322           -11.314658   \n",
       "124             2.564047    -35.154307           -16.082588   \n",
       "125             2.824672    -40.290879           -20.924246   \n",
       "126            -5.376613    -39.013132           -24.542023   \n",
       "...                  ...           ...                  ...   \n",
       "2011            0.126806      0.741691             7.910342   \n",
       "2012           -0.325815     -7.771069             4.774060   \n",
       "2013           -1.271892    -15.419817             0.735284   \n",
       "2014           -1.876834    -12.175545            -1.846882   \n",
       "2015           -2.232085      2.831380            -0.911229   \n",
       "\n",
       "Price  momentum_pvo_hist  momentum_kama   others_dr  others_dlr   others_cr  \\\n",
       "122           -21.734010       0.204269   11.109626   10.534715  384.260507   \n",
       "123           -22.109663       0.211888    0.000000    0.000000  384.260507   \n",
       "124           -19.071718       0.211124  -85.133890 -190.608608  -28.009302   \n",
       "125           -19.366632       0.213051  572.670944  190.608608  384.260507   \n",
       "126           -14.471109       0.212265  -82.860345 -176.377539  -16.999419   \n",
       "...                  ...            ...         ...         ...         ...   \n",
       "2011           -7.168651       0.050643    0.000000    0.000000    6.609809   \n",
       "2012          -12.545129       0.050950    0.000000    0.000000    6.609809   \n",
       "2013          -16.155101       0.050823   -9.090907   -9.531016   -3.081990   \n",
       "2014          -10.328664       0.050765    0.000000    0.000000   -3.081990   \n",
       "2015            3.742609       0.050711    0.000000    0.000000   -3.081990   \n",
       "\n",
       "Price      Return  \n",
       "122           NaN  \n",
       "123      0.000000  \n",
       "124    -85.133890  \n",
       "125    572.670944  \n",
       "126    -82.860345  \n",
       "...           ...  \n",
       "2011     0.000000  \n",
       "2012     0.000000  \n",
       "2013    -9.090907  \n",
       "2014     0.000000  \n",
       "2015     0.000000  \n",
       "\n",
       "[1894 rows x 94 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77babf3e-a97d-455f-913b-3817df0882ae",
   "metadata": {},
   "source": [
    "**Separate features and target df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b3ef87-f319-4694-85d9-2ac44c413aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = df_clean['Target']\n",
    "features_df = df_clean.drop(columns = [\"Date\", \"Target\"])\n",
    "df_clean = df_clean.drop(columns = [\"Date\"]) # date must be removed in any case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19563fd5-b786-4bc1-ac34-f7e5446fcb8a",
   "metadata": {},
   "source": [
    "**Combine loaded data (if desired) or transform data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bf0f7-0d92-4504-9a03-f8a1005c8ced",
   "metadata": {},
   "source": [
    "If you want to **perform PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccef5a6-7cdb-4480-873a-a11e30119176",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_filename = filename[:-4]\n",
    "final_df = df_clean\n",
    "if processing_method == \"pca\":\n",
    "    from _0_process_data._01_pca import generate_rotated_pca_df\n",
    "    pca_data_dir = os.path.join(transformed_data_dir, \"pca\")\n",
    "    pca_df = generate_rotated_pca_df(features_df, target_df)\n",
    "    final_df = pca_df\n",
    "\n",
    "    pca_filename = 'pca_' + str(filename)\n",
    "    horizontal_filename = pca_filename[:-4]\n",
    "    pca_df.to_csv(os.path.join(pca_data_dir, pca_filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a06d55-39f9-4fad-8490-3664bd2bcb5a",
   "metadata": {},
   "source": [
    "**Convert to appropiate data structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a53e42-17ee-4882-835f-6db43d9ddf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from _0_process_data._02_build_horizontal_df import split_dataframe, create_sequential_dataframe\n",
    "\n",
    "window_size = 200\n",
    "sequential_data, targets = split_dataframe(final_df, target_column='Target', window_size=window_size)\n",
    "reshaped_df = create_sequential_dataframe(sequential_data, targets)\n",
    "\n",
    "pkl_filename = f'{horizontal_filename}_{window_size}.pkl'\n",
    "if data_type == \"stock_single_name\":\n",
    "    structured_folder = os.path.join(structured_data_dir, \"single_names\")\n",
    "elif data_type == \"stock_technical_ind\":\n",
    "    structured_folder = os.path.join(structured_data_dir, \"technical\")\n",
    "    \n",
    "reshaped_df.to_pickle(os.path.join(structured_folder, pkl_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66925bf2-c9db-4c72-9bfa-4a8629e35fd8",
   "metadata": {},
   "source": [
    "## **2. Models**\n",
    "\n",
    "This part of the code structures the process of introducing the loaded data into a precise model. At the moment, standardized for:\n",
    "\n",
    "    - Objective: (GRU)\n",
    "    - Objective: ARIMA / GARCH \n",
    "    \n",
    "Parameters in this part of the code:\n",
    "\n",
    "    - Model\n",
    "    - Date it was performed\n",
    "    - Learning rate\n",
    "    - Num epochs\n",
    "    - Execution time\n",
    "    - Number of layers \n",
    "    - And more..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8da749-9e10-42eb-8149-fe18dd7bcbac",
   "metadata": {},
   "source": [
    "**Choose model that will be run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b4fbac8-8073-4fca-b66e-0bde453f0743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"gru\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae123f-6571-45fc-a671-1f367272d582",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5f5128-efa3-4d3f-822d-79fa60867cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_df = pd.read_pickle(os.path.join(structured_folder, pkl_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80fd86a-218d-4334-902b-b1c6ed08e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "      <th>Return</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...</td>\n",
       "      <td>0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...</td>\n",
       "      <td>0      3.034827\n",
       "1     -0.289834\n",
       "2      3.03482...</td>\n",
       "      <td>0      3.359722\n",
       "1     -0.267826\n",
       "2      3.35972...</td>\n",
       "      <td>0      3.197826\n",
       "1     -0.278824\n",
       "2      3.19782...</td>\n",
       "      <td>0     -0.188423\n",
       "1     -0.165805\n",
       "2     -0.18816...</td>\n",
       "      <td>0      3.810811\n",
       "1      3.810811\n",
       "2      3.81081...</td>\n",
       "      <td>0     -4.219257\n",
       "1     -4.220382\n",
       "2     -4.22026...</td>\n",
       "      <td>0      0.491881\n",
       "1      0.366707\n",
       "2      0.36646...</td>\n",
       "      <td>0     -0.046111\n",
       "1     -0.099986\n",
       "2     -0.08703...</td>\n",
       "      <td>...</td>\n",
       "      <td>0      3.328003\n",
       "1      0.616139\n",
       "2      0.67769...</td>\n",
       "      <td>0     -0.749476\n",
       "1     -0.805436\n",
       "2     -0.97158...</td>\n",
       "      <td>0     -0.044259\n",
       "1     -0.244842\n",
       "2     -0.44852...</td>\n",
       "      <td>0     -1.251222\n",
       "1     -1.079365\n",
       "2     -1.09604...</td>\n",
       "      <td>0      2.123750\n",
       "1      2.112859\n",
       "2      2.14034...</td>\n",
       "      <td>0     -0.181028\n",
       "1     -0.821313\n",
       "2      4.12598...</td>\n",
       "      <td>0      0.001424\n",
       "1     -3.189657\n",
       "2      3.19250...</td>\n",
       "      <td>0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...</td>\n",
       "      <td>0      0.260222\n",
       "1     -0.423366\n",
       "2     -1.10695...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...</td>\n",
       "      <td>0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...</td>\n",
       "      <td>0     -0.289834\n",
       "1      3.034827\n",
       "2     -0.20104...</td>\n",
       "      <td>0     -0.267826\n",
       "1      3.359722\n",
       "2     -0.18851...</td>\n",
       "      <td>0     -0.278824\n",
       "1      3.197826\n",
       "2     -0.20281...</td>\n",
       "      <td>0     -0.165805\n",
       "1     -0.188165\n",
       "2     -0.15633...</td>\n",
       "      <td>0      3.810811\n",
       "1      3.810811\n",
       "2      3.81664...</td>\n",
       "      <td>0     -4.220382\n",
       "1     -4.220266\n",
       "2     -4.22181...</td>\n",
       "      <td>0      0.366707\n",
       "1      0.366463\n",
       "2      0.72695...</td>\n",
       "      <td>0     -0.099986\n",
       "1     -0.087038\n",
       "2     -0.15345...</td>\n",
       "      <td>...</td>\n",
       "      <td>0      0.616139\n",
       "1      0.677695\n",
       "2     -1.25931...</td>\n",
       "      <td>0     -0.805436\n",
       "1     -0.971587\n",
       "2     -0.93025...</td>\n",
       "      <td>0     -0.244842\n",
       "1     -0.448527\n",
       "2     -0.60072...</td>\n",
       "      <td>0     -1.079365\n",
       "1     -1.096048\n",
       "2     -0.81910...</td>\n",
       "      <td>0      2.112859\n",
       "1      2.140340\n",
       "2      2.12913...</td>\n",
       "      <td>0     -0.821313\n",
       "1      4.125984\n",
       "2     -0.80421...</td>\n",
       "      <td>0     -3.189657\n",
       "1      3.192504\n",
       "2     -2.95140...</td>\n",
       "      <td>0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...</td>\n",
       "      <td>0     -0.423366\n",
       "1     -1.106955\n",
       "2     -1.79054...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...</td>\n",
       "      <td>0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...</td>\n",
       "      <td>0      3.034827\n",
       "1     -0.201047\n",
       "2     -0.22527...</td>\n",
       "      <td>0      3.359722\n",
       "1     -0.188518\n",
       "2     -0.19738...</td>\n",
       "      <td>0      3.197826\n",
       "1     -0.202815\n",
       "2     -0.21131...</td>\n",
       "      <td>0     -0.188165\n",
       "1     -0.156330\n",
       "2     -0.14087...</td>\n",
       "      <td>0      3.810811\n",
       "1      3.816646\n",
       "2      3.81664...</td>\n",
       "      <td>0     -4.220266\n",
       "1     -4.221819\n",
       "2     -4.22406...</td>\n",
       "      <td>0      0.366463\n",
       "1      0.726950\n",
       "2      0.80268...</td>\n",
       "      <td>0     -0.087038\n",
       "1     -0.153458\n",
       "2     -0.13918...</td>\n",
       "      <td>...</td>\n",
       "      <td>0      0.677695\n",
       "1     -1.259316\n",
       "2     -2.60268...</td>\n",
       "      <td>0     -0.971587\n",
       "1     -0.930257\n",
       "2     -0.79743...</td>\n",
       "      <td>0     -0.448527\n",
       "1     -0.600725\n",
       "2     -0.68793...</td>\n",
       "      <td>0     -1.096048\n",
       "1     -0.819107\n",
       "2     -0.46954...</td>\n",
       "      <td>0      2.140340\n",
       "1      2.129134\n",
       "2      2.11798...</td>\n",
       "      <td>0      4.125984\n",
       "1     -0.804214\n",
       "2     -0.20825...</td>\n",
       "      <td>0      3.192504\n",
       "1     -2.951407\n",
       "2     -0.06030...</td>\n",
       "      <td>0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...</td>\n",
       "      <td>0     -1.106955\n",
       "1     -1.790544\n",
       "2     -2.47413...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...</td>\n",
       "      <td>0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...</td>\n",
       "      <td>0     -0.201047\n",
       "1     -0.225276\n",
       "2     -0.22527...</td>\n",
       "      <td>0     -0.188518\n",
       "1     -0.197387\n",
       "2     -0.19738...</td>\n",
       "      <td>0     -0.202815\n",
       "1     -0.211315\n",
       "2     -0.21131...</td>\n",
       "      <td>0     -0.156330\n",
       "1     -0.140871\n",
       "2     -0.17515...</td>\n",
       "      <td>0      3.816646\n",
       "1      3.816646\n",
       "2      3.81664...</td>\n",
       "      <td>0     -4.221819\n",
       "1     -4.224069\n",
       "2     -4.22336...</td>\n",
       "      <td>0      0.726950\n",
       "1      0.802681\n",
       "2      0.79678...</td>\n",
       "      <td>0     -0.153458\n",
       "1     -0.139185\n",
       "2     -0.12617...</td>\n",
       "      <td>...</td>\n",
       "      <td>0     -1.259316\n",
       "1     -2.602683\n",
       "2     -3.47408...</td>\n",
       "      <td>0     -0.930257\n",
       "1     -0.797434\n",
       "2     -0.88119...</td>\n",
       "      <td>0     -0.600725\n",
       "1     -0.687933\n",
       "2     -0.77948...</td>\n",
       "      <td>0     -0.819107\n",
       "1     -0.469548\n",
       "2     -0.49292...</td>\n",
       "      <td>0      2.129134\n",
       "1      2.117982\n",
       "2      1.93224...</td>\n",
       "      <td>0     -0.804214\n",
       "1     -0.208252\n",
       "2     -0.18102...</td>\n",
       "      <td>0     -2.951407\n",
       "1     -0.060302\n",
       "2      0.00142...</td>\n",
       "      <td>0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...</td>\n",
       "      <td>0     -1.790544\n",
       "1     -2.474132\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...</td>\n",
       "      <td>0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...</td>\n",
       "      <td>0     -0.225276\n",
       "1     -0.225276\n",
       "2     -0.26560...</td>\n",
       "      <td>0     -0.197387\n",
       "1     -0.197387\n",
       "2     -0.24139...</td>\n",
       "      <td>0     -0.211315\n",
       "1     -0.211315\n",
       "2     -0.25348...</td>\n",
       "      <td>0     -0.140871\n",
       "1     -0.175156\n",
       "2     -0.14087...</td>\n",
       "      <td>0      3.816646\n",
       "1      3.816646\n",
       "2      3.81664...</td>\n",
       "      <td>0     -4.224069\n",
       "1     -4.223365\n",
       "2     -4.22561...</td>\n",
       "      <td>0      0.802681\n",
       "1      0.796788\n",
       "2     -0.20641...</td>\n",
       "      <td>0     -0.139185\n",
       "1     -0.126170\n",
       "2     -0.11631...</td>\n",
       "      <td>...</td>\n",
       "      <td>0     -2.602683\n",
       "1     -3.474080\n",
       "2     -4.02361...</td>\n",
       "      <td>0     -0.797434\n",
       "1     -0.881198\n",
       "2     -0.73511...</td>\n",
       "      <td>0     -0.687933\n",
       "1     -0.779489\n",
       "2     -0.81473...</td>\n",
       "      <td>0     -0.469548\n",
       "1     -0.492927\n",
       "2     -0.19004...</td>\n",
       "      <td>0      2.117982\n",
       "1      1.932246\n",
       "2      1.79019...</td>\n",
       "      <td>0     -0.208252\n",
       "1     -0.181028\n",
       "2     -0.22804...</td>\n",
       "      <td>0     -0.060302\n",
       "1      0.001424\n",
       "2     -0.10665...</td>\n",
       "      <td>0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...</td>\n",
       "      <td>0     -2.474132\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...</td>\n",
       "      <td>0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...</td>\n",
       "      <td>0     -0.088813\n",
       "1     -0.760967\n",
       "2     -0.76096...</td>\n",
       "      <td>0     -0.133770\n",
       "1     -0.781881\n",
       "2     -0.78188...</td>\n",
       "      <td>0     -0.068613\n",
       "1     -0.771495\n",
       "2     -0.77149...</td>\n",
       "      <td>0     -0.177005\n",
       "1     -0.126425\n",
       "2     -0.19074...</td>\n",
       "      <td>0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...</td>\n",
       "      <td>0      0.494024\n",
       "1      0.491122\n",
       "2      0.49112...</td>\n",
       "      <td>0      0.362194\n",
       "1      0.357152\n",
       "2      0.35715...</td>\n",
       "      <td>0     -0.166668\n",
       "1     -0.174425\n",
       "2     -0.15637...</td>\n",
       "      <td>...</td>\n",
       "      <td>0      1.506760\n",
       "1     -0.188886\n",
       "2     -1.38488...</td>\n",
       "      <td>0      0.671180\n",
       "1      0.479920\n",
       "2      0.18847...</td>\n",
       "      <td>0      0.933665\n",
       "1      0.871836\n",
       "2      0.74656...</td>\n",
       "      <td>0     -0.081688\n",
       "1     -0.333036\n",
       "2     -0.67429...</td>\n",
       "      <td>0     -0.545746\n",
       "1     -0.547023\n",
       "2     -0.54829...</td>\n",
       "      <td>0     -0.317772\n",
       "1     -0.816128\n",
       "2     -0.18102...</td>\n",
       "      <td>0     -0.334530\n",
       "1     -3.113762\n",
       "2      0.00142...</td>\n",
       "      <td>0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...</td>\n",
       "      <td>0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.760967\n",
       "1     -0.760967\n",
       "2     -0.08881...</td>\n",
       "      <td>0     -0.781881\n",
       "1     -0.781881\n",
       "2     -0.04849...</td>\n",
       "      <td>0     -0.771495\n",
       "1     -0.771495\n",
       "2     -0.06861...</td>\n",
       "      <td>0     -0.126425\n",
       "1     -0.190740\n",
       "2     -0.18044...</td>\n",
       "      <td>0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...</td>\n",
       "      <td>0      0.491122\n",
       "1      0.491122\n",
       "2      0.49158...</td>\n",
       "      <td>0      0.357152\n",
       "1      0.357152\n",
       "2      0.35691...</td>\n",
       "      <td>0     -0.174425\n",
       "1     -0.156376\n",
       "2     -0.13643...</td>\n",
       "      <td>...</td>\n",
       "      <td>0     -0.188886\n",
       "1     -1.384887\n",
       "2     -0.01907...</td>\n",
       "      <td>0      0.479920\n",
       "1      0.188470\n",
       "2     -0.05347...</td>\n",
       "      <td>0      0.871836\n",
       "1      0.746563\n",
       "2      0.58341...</td>\n",
       "      <td>0     -0.333036\n",
       "1     -0.674290\n",
       "2     -0.87802...</td>\n",
       "      <td>0     -0.547023\n",
       "1     -0.548294\n",
       "2     -0.53712...</td>\n",
       "      <td>0     -0.816128\n",
       "1     -0.181028\n",
       "2      4.43896...</td>\n",
       "      <td>0     -3.113762\n",
       "1      0.001424\n",
       "2      3.29299...</td>\n",
       "      <td>0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...</td>\n",
       "      <td>0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.760967\n",
       "1     -0.088813\n",
       "2     -0.08881...</td>\n",
       "      <td>0     -0.781881\n",
       "1     -0.048492\n",
       "2     -0.04849...</td>\n",
       "      <td>0     -0.771495\n",
       "1     -0.068613\n",
       "2     -0.06861...</td>\n",
       "      <td>0     -0.190740\n",
       "1     -0.180449\n",
       "2     -0.19074...</td>\n",
       "      <td>0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...</td>\n",
       "      <td>0      0.491122\n",
       "1      0.491586\n",
       "2      0.49158...</td>\n",
       "      <td>0      0.357152\n",
       "1      0.356910\n",
       "2      0.35691...</td>\n",
       "      <td>0     -0.156376\n",
       "1     -0.136434\n",
       "2     -0.12381...</td>\n",
       "      <td>...</td>\n",
       "      <td>0     -1.384887\n",
       "1     -0.019075\n",
       "2      0.78670...</td>\n",
       "      <td>0      0.188470\n",
       "1     -0.053470\n",
       "2     -0.29896...</td>\n",
       "      <td>0      0.746563\n",
       "1      0.583412\n",
       "2      0.38903...</td>\n",
       "      <td>0     -0.674290\n",
       "1     -0.878023\n",
       "2     -1.04598...</td>\n",
       "      <td>0     -0.548294\n",
       "1     -0.537123\n",
       "2     -0.53565...</td>\n",
       "      <td>0     -0.181028\n",
       "1      4.438965\n",
       "2     -0.18102...</td>\n",
       "      <td>0      0.001424\n",
       "1      3.292998\n",
       "2      0.00142...</td>\n",
       "      <td>0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0     -0.088813\n",
       "1     -0.088813\n",
       "2     -0.08881...</td>\n",
       "      <td>0     -0.048492\n",
       "1     -0.048492\n",
       "2     -0.04849...</td>\n",
       "      <td>0     -0.068613\n",
       "1     -0.068613\n",
       "2     -0.06861...</td>\n",
       "      <td>0     -0.180449\n",
       "1     -0.190740\n",
       "2     -0.12771...</td>\n",
       "      <td>0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...</td>\n",
       "      <td>0      0.491586\n",
       "1      0.491586\n",
       "2      0.49443...</td>\n",
       "      <td>0      0.356910\n",
       "1      0.356910\n",
       "2      0.38585...</td>\n",
       "      <td>0     -0.136434\n",
       "1     -0.123812\n",
       "2     -0.11299...</td>\n",
       "      <td>...</td>\n",
       "      <td>0     -0.019075\n",
       "1      0.786707\n",
       "2      1.21428...</td>\n",
       "      <td>0     -0.053470\n",
       "1     -0.298966\n",
       "2     -0.33736...</td>\n",
       "      <td>0      0.583412\n",
       "1      0.389034\n",
       "2      0.22354...</td>\n",
       "      <td>0     -0.878023\n",
       "1     -1.045986\n",
       "2     -0.89060...</td>\n",
       "      <td>0     -0.537123\n",
       "1     -0.535655\n",
       "2     -0.51454...</td>\n",
       "      <td>0      4.438965\n",
       "1     -0.181028\n",
       "2     -0.18102...</td>\n",
       "      <td>0      3.292998\n",
       "1      0.001424\n",
       "2      0.00142...</td>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...</td>\n",
       "      <td>0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...</td>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...</td>\n",
       "      <td>0     -0.088813\n",
       "1     -0.088813\n",
       "2     -0.76096...</td>\n",
       "      <td>0     -0.048492\n",
       "1     -0.048492\n",
       "2     -0.78188...</td>\n",
       "      <td>0     -0.068613\n",
       "1     -0.068613\n",
       "2     -0.77149...</td>\n",
       "      <td>0     -0.190740\n",
       "1     -0.127711\n",
       "2     -0.19074...</td>\n",
       "      <td>0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...</td>\n",
       "      <td>0      0.491586\n",
       "1      0.494430\n",
       "2      0.49443...</td>\n",
       "      <td>0      0.356910\n",
       "1      0.385857\n",
       "2      0.31969...</td>\n",
       "      <td>0     -0.123812\n",
       "1     -0.112994\n",
       "2     -0.10372...</td>\n",
       "      <td>...</td>\n",
       "      <td>0      0.786707\n",
       "1      1.214281\n",
       "2     -0.40105...</td>\n",
       "      <td>0     -0.298966\n",
       "1     -0.337363\n",
       "2     -0.55840...</td>\n",
       "      <td>0      0.389034\n",
       "1      0.223545\n",
       "2      0.03365...</td>\n",
       "      <td>0     -1.045986\n",
       "1     -0.890604\n",
       "2     -1.02183...</td>\n",
       "      <td>0     -0.535655\n",
       "1     -0.514547\n",
       "2     -0.51572...</td>\n",
       "      <td>0     -0.181028\n",
       "1     -0.181028\n",
       "2     -0.82782...</td>\n",
       "      <td>0      0.001424\n",
       "1      0.001424\n",
       "2     -3.29015...</td>\n",
       "      <td>0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...</td>\n",
       "      <td>0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1693 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Adj Close  \\\n",
       "0     0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...   \n",
       "1     0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...   \n",
       "2     0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...   \n",
       "3     0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...   \n",
       "4     0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...   \n",
       "1689  0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...   \n",
       "1690  0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1691  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1692  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...   \n",
       "\n",
       "                                                  Close  \\\n",
       "0     0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...   \n",
       "1     0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...   \n",
       "2     0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...   \n",
       "3     0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...   \n",
       "4     0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...   \n",
       "1689  0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...   \n",
       "1690  0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1691  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1692  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...   \n",
       "\n",
       "                                                   High  \\\n",
       "0     0      3.034827\n",
       "1     -0.289834\n",
       "2      3.03482...   \n",
       "1     0     -0.289834\n",
       "1      3.034827\n",
       "2     -0.20104...   \n",
       "2     0      3.034827\n",
       "1     -0.201047\n",
       "2     -0.22527...   \n",
       "3     0     -0.201047\n",
       "1     -0.225276\n",
       "2     -0.22527...   \n",
       "4     0     -0.225276\n",
       "1     -0.225276\n",
       "2     -0.26560...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.088813\n",
       "1     -0.760967\n",
       "2     -0.76096...   \n",
       "1689  0     -0.760967\n",
       "1     -0.760967\n",
       "2     -0.08881...   \n",
       "1690  0     -0.760967\n",
       "1     -0.088813\n",
       "2     -0.08881...   \n",
       "1691  0     -0.088813\n",
       "1     -0.088813\n",
       "2     -0.08881...   \n",
       "1692  0     -0.088813\n",
       "1     -0.088813\n",
       "2     -0.76096...   \n",
       "\n",
       "                                                    Low  \\\n",
       "0     0      3.359722\n",
       "1     -0.267826\n",
       "2      3.35972...   \n",
       "1     0     -0.267826\n",
       "1      3.359722\n",
       "2     -0.18851...   \n",
       "2     0      3.359722\n",
       "1     -0.188518\n",
       "2     -0.19738...   \n",
       "3     0     -0.188518\n",
       "1     -0.197387\n",
       "2     -0.19738...   \n",
       "4     0     -0.197387\n",
       "1     -0.197387\n",
       "2     -0.24139...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.133770\n",
       "1     -0.781881\n",
       "2     -0.78188...   \n",
       "1689  0     -0.781881\n",
       "1     -0.781881\n",
       "2     -0.04849...   \n",
       "1690  0     -0.781881\n",
       "1     -0.048492\n",
       "2     -0.04849...   \n",
       "1691  0     -0.048492\n",
       "1     -0.048492\n",
       "2     -0.04849...   \n",
       "1692  0     -0.048492\n",
       "1     -0.048492\n",
       "2     -0.78188...   \n",
       "\n",
       "                                                   Open  \\\n",
       "0     0      3.197826\n",
       "1     -0.278824\n",
       "2      3.19782...   \n",
       "1     0     -0.278824\n",
       "1      3.197826\n",
       "2     -0.20281...   \n",
       "2     0      3.197826\n",
       "1     -0.202815\n",
       "2     -0.21131...   \n",
       "3     0     -0.202815\n",
       "1     -0.211315\n",
       "2     -0.21131...   \n",
       "4     0     -0.211315\n",
       "1     -0.211315\n",
       "2     -0.25348...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.068613\n",
       "1     -0.771495\n",
       "2     -0.77149...   \n",
       "1689  0     -0.771495\n",
       "1     -0.771495\n",
       "2     -0.06861...   \n",
       "1690  0     -0.771495\n",
       "1     -0.068613\n",
       "2     -0.06861...   \n",
       "1691  0     -0.068613\n",
       "1     -0.068613\n",
       "2     -0.06861...   \n",
       "1692  0     -0.068613\n",
       "1     -0.068613\n",
       "2     -0.77149...   \n",
       "\n",
       "                                                 Volume  \\\n",
       "0     0     -0.188423\n",
       "1     -0.165805\n",
       "2     -0.18816...   \n",
       "1     0     -0.165805\n",
       "1     -0.188165\n",
       "2     -0.15633...   \n",
       "2     0     -0.188165\n",
       "1     -0.156330\n",
       "2     -0.14087...   \n",
       "3     0     -0.156330\n",
       "1     -0.140871\n",
       "2     -0.17515...   \n",
       "4     0     -0.140871\n",
       "1     -0.175156\n",
       "2     -0.14087...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.177005\n",
       "1     -0.126425\n",
       "2     -0.19074...   \n",
       "1689  0     -0.126425\n",
       "1     -0.190740\n",
       "2     -0.18044...   \n",
       "1690  0     -0.190740\n",
       "1     -0.180449\n",
       "2     -0.19074...   \n",
       "1691  0     -0.180449\n",
       "1     -0.190740\n",
       "2     -0.12771...   \n",
       "1692  0     -0.190740\n",
       "1     -0.127711\n",
       "2     -0.19074...   \n",
       "\n",
       "                                             volume_adi  \\\n",
       "0     0      3.810811\n",
       "1      3.810811\n",
       "2      3.81081...   \n",
       "1     0      3.810811\n",
       "1      3.810811\n",
       "2      3.81664...   \n",
       "2     0      3.810811\n",
       "1      3.816646\n",
       "2      3.81664...   \n",
       "3     0      3.816646\n",
       "1      3.816646\n",
       "2      3.81664...   \n",
       "4     0      3.816646\n",
       "1      3.816646\n",
       "2      3.81664...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...   \n",
       "1689  0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...   \n",
       "1690  0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...   \n",
       "1691  0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...   \n",
       "1692  0     -0.367789\n",
       "1     -0.367789\n",
       "2     -0.36778...   \n",
       "\n",
       "                                             volume_obv  \\\n",
       "0     0     -4.219257\n",
       "1     -4.220382\n",
       "2     -4.22026...   \n",
       "1     0     -4.220382\n",
       "1     -4.220266\n",
       "2     -4.22181...   \n",
       "2     0     -4.220266\n",
       "1     -4.221819\n",
       "2     -4.22406...   \n",
       "3     0     -4.221819\n",
       "1     -4.224069\n",
       "2     -4.22336...   \n",
       "4     0     -4.224069\n",
       "1     -4.223365\n",
       "2     -4.22561...   \n",
       "...                                                 ...   \n",
       "1688  0      0.494024\n",
       "1      0.491122\n",
       "2      0.49112...   \n",
       "1689  0      0.491122\n",
       "1      0.491122\n",
       "2      0.49158...   \n",
       "1690  0      0.491122\n",
       "1      0.491586\n",
       "2      0.49158...   \n",
       "1691  0      0.491586\n",
       "1      0.491586\n",
       "2      0.49443...   \n",
       "1692  0      0.491586\n",
       "1      0.494430\n",
       "2      0.49443...   \n",
       "\n",
       "                                             volume_cmf  \\\n",
       "0     0      0.491881\n",
       "1      0.366707\n",
       "2      0.36646...   \n",
       "1     0      0.366707\n",
       "1      0.366463\n",
       "2      0.72695...   \n",
       "2     0      0.366463\n",
       "1      0.726950\n",
       "2      0.80268...   \n",
       "3     0      0.726950\n",
       "1      0.802681\n",
       "2      0.79678...   \n",
       "4     0      0.802681\n",
       "1      0.796788\n",
       "2     -0.20641...   \n",
       "...                                                 ...   \n",
       "1688  0      0.362194\n",
       "1      0.357152\n",
       "2      0.35715...   \n",
       "1689  0      0.357152\n",
       "1      0.357152\n",
       "2      0.35691...   \n",
       "1690  0      0.357152\n",
       "1      0.356910\n",
       "2      0.35691...   \n",
       "1691  0      0.356910\n",
       "1      0.356910\n",
       "2      0.38585...   \n",
       "1692  0      0.356910\n",
       "1      0.385857\n",
       "2      0.31969...   \n",
       "\n",
       "                                              volume_fi  ...  \\\n",
       "0     0     -0.046111\n",
       "1     -0.099986\n",
       "2     -0.08703...  ...   \n",
       "1     0     -0.099986\n",
       "1     -0.087038\n",
       "2     -0.15345...  ...   \n",
       "2     0     -0.087038\n",
       "1     -0.153458\n",
       "2     -0.13918...  ...   \n",
       "3     0     -0.153458\n",
       "1     -0.139185\n",
       "2     -0.12617...  ...   \n",
       "4     0     -0.139185\n",
       "1     -0.126170\n",
       "2     -0.11631...  ...   \n",
       "...                                                 ...  ...   \n",
       "1688  0     -0.166668\n",
       "1     -0.174425\n",
       "2     -0.15637...  ...   \n",
       "1689  0     -0.174425\n",
       "1     -0.156376\n",
       "2     -0.13643...  ...   \n",
       "1690  0     -0.156376\n",
       "1     -0.136434\n",
       "2     -0.12381...  ...   \n",
       "1691  0     -0.136434\n",
       "1     -0.123812\n",
       "2     -0.11299...  ...   \n",
       "1692  0     -0.123812\n",
       "1     -0.112994\n",
       "2     -0.10372...  ...   \n",
       "\n",
       "                                      momentum_ppo_hist  \\\n",
       "0     0      3.328003\n",
       "1      0.616139\n",
       "2      0.67769...   \n",
       "1     0      0.616139\n",
       "1      0.677695\n",
       "2     -1.25931...   \n",
       "2     0      0.677695\n",
       "1     -1.259316\n",
       "2     -2.60268...   \n",
       "3     0     -1.259316\n",
       "1     -2.602683\n",
       "2     -3.47408...   \n",
       "4     0     -2.602683\n",
       "1     -3.474080\n",
       "2     -4.02361...   \n",
       "...                                                 ...   \n",
       "1688  0      1.506760\n",
       "1     -0.188886\n",
       "2     -1.38488...   \n",
       "1689  0     -0.188886\n",
       "1     -1.384887\n",
       "2     -0.01907...   \n",
       "1690  0     -1.384887\n",
       "1     -0.019075\n",
       "2      0.78670...   \n",
       "1691  0     -0.019075\n",
       "1      0.786707\n",
       "2      1.21428...   \n",
       "1692  0      0.786707\n",
       "1      1.214281\n",
       "2     -0.40105...   \n",
       "\n",
       "                                           momentum_pvo  \\\n",
       "0     0     -0.749476\n",
       "1     -0.805436\n",
       "2     -0.97158...   \n",
       "1     0     -0.805436\n",
       "1     -0.971587\n",
       "2     -0.93025...   \n",
       "2     0     -0.971587\n",
       "1     -0.930257\n",
       "2     -0.79743...   \n",
       "3     0     -0.930257\n",
       "1     -0.797434\n",
       "2     -0.88119...   \n",
       "4     0     -0.797434\n",
       "1     -0.881198\n",
       "2     -0.73511...   \n",
       "...                                                 ...   \n",
       "1688  0      0.671180\n",
       "1      0.479920\n",
       "2      0.18847...   \n",
       "1689  0      0.479920\n",
       "1      0.188470\n",
       "2     -0.05347...   \n",
       "1690  0      0.188470\n",
       "1     -0.053470\n",
       "2     -0.29896...   \n",
       "1691  0     -0.053470\n",
       "1     -0.298966\n",
       "2     -0.33736...   \n",
       "1692  0     -0.298966\n",
       "1     -0.337363\n",
       "2     -0.55840...   \n",
       "\n",
       "                                    momentum_pvo_signal  \\\n",
       "0     0     -0.044259\n",
       "1     -0.244842\n",
       "2     -0.44852...   \n",
       "1     0     -0.244842\n",
       "1     -0.448527\n",
       "2     -0.60072...   \n",
       "2     0     -0.448527\n",
       "1     -0.600725\n",
       "2     -0.68793...   \n",
       "3     0     -0.600725\n",
       "1     -0.687933\n",
       "2     -0.77948...   \n",
       "4     0     -0.687933\n",
       "1     -0.779489\n",
       "2     -0.81473...   \n",
       "...                                                 ...   \n",
       "1688  0      0.933665\n",
       "1      0.871836\n",
       "2      0.74656...   \n",
       "1689  0      0.871836\n",
       "1      0.746563\n",
       "2      0.58341...   \n",
       "1690  0      0.746563\n",
       "1      0.583412\n",
       "2      0.38903...   \n",
       "1691  0      0.583412\n",
       "1      0.389034\n",
       "2      0.22354...   \n",
       "1692  0      0.389034\n",
       "1      0.223545\n",
       "2      0.03365...   \n",
       "\n",
       "                                      momentum_pvo_hist  \\\n",
       "0     0     -1.251222\n",
       "1     -1.079365\n",
       "2     -1.09604...   \n",
       "1     0     -1.079365\n",
       "1     -1.096048\n",
       "2     -0.81910...   \n",
       "2     0     -1.096048\n",
       "1     -0.819107\n",
       "2     -0.46954...   \n",
       "3     0     -0.819107\n",
       "1     -0.469548\n",
       "2     -0.49292...   \n",
       "4     0     -0.469548\n",
       "1     -0.492927\n",
       "2     -0.19004...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.081688\n",
       "1     -0.333036\n",
       "2     -0.67429...   \n",
       "1689  0     -0.333036\n",
       "1     -0.674290\n",
       "2     -0.87802...   \n",
       "1690  0     -0.674290\n",
       "1     -0.878023\n",
       "2     -1.04598...   \n",
       "1691  0     -0.878023\n",
       "1     -1.045986\n",
       "2     -0.89060...   \n",
       "1692  0     -1.045986\n",
       "1     -0.890604\n",
       "2     -1.02183...   \n",
       "\n",
       "                                          momentum_kama  \\\n",
       "0     0      2.123750\n",
       "1      2.112859\n",
       "2      2.14034...   \n",
       "1     0      2.112859\n",
       "1      2.140340\n",
       "2      2.12913...   \n",
       "2     0      2.140340\n",
       "1      2.129134\n",
       "2      2.11798...   \n",
       "3     0      2.129134\n",
       "1      2.117982\n",
       "2      1.93224...   \n",
       "4     0      2.117982\n",
       "1      1.932246\n",
       "2      1.79019...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.545746\n",
       "1     -0.547023\n",
       "2     -0.54829...   \n",
       "1689  0     -0.547023\n",
       "1     -0.548294\n",
       "2     -0.53712...   \n",
       "1690  0     -0.548294\n",
       "1     -0.537123\n",
       "2     -0.53565...   \n",
       "1691  0     -0.537123\n",
       "1     -0.535655\n",
       "2     -0.51454...   \n",
       "1692  0     -0.535655\n",
       "1     -0.514547\n",
       "2     -0.51572...   \n",
       "\n",
       "                                              others_dr  \\\n",
       "0     0     -0.181028\n",
       "1     -0.821313\n",
       "2      4.12598...   \n",
       "1     0     -0.821313\n",
       "1      4.125984\n",
       "2     -0.80421...   \n",
       "2     0      4.125984\n",
       "1     -0.804214\n",
       "2     -0.20825...   \n",
       "3     0     -0.804214\n",
       "1     -0.208252\n",
       "2     -0.18102...   \n",
       "4     0     -0.208252\n",
       "1     -0.181028\n",
       "2     -0.22804...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.317772\n",
       "1     -0.816128\n",
       "2     -0.18102...   \n",
       "1689  0     -0.816128\n",
       "1     -0.181028\n",
       "2      4.43896...   \n",
       "1690  0     -0.181028\n",
       "1      4.438965\n",
       "2     -0.18102...   \n",
       "1691  0      4.438965\n",
       "1     -0.181028\n",
       "2     -0.18102...   \n",
       "1692  0     -0.181028\n",
       "1     -0.181028\n",
       "2     -0.82782...   \n",
       "\n",
       "                                             others_dlr  \\\n",
       "0     0      0.001424\n",
       "1     -3.189657\n",
       "2      3.19250...   \n",
       "1     0     -3.189657\n",
       "1      3.192504\n",
       "2     -2.95140...   \n",
       "2     0      3.192504\n",
       "1     -2.951407\n",
       "2     -0.06030...   \n",
       "3     0     -2.951407\n",
       "1     -0.060302\n",
       "2      0.00142...   \n",
       "4     0     -0.060302\n",
       "1      0.001424\n",
       "2     -0.10665...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.334530\n",
       "1     -3.113762\n",
       "2      0.00142...   \n",
       "1689  0     -3.113762\n",
       "1      0.001424\n",
       "2      3.29299...   \n",
       "1690  0      0.001424\n",
       "1      3.292998\n",
       "2      0.00142...   \n",
       "1691  0      3.292998\n",
       "1      0.001424\n",
       "2      0.00142...   \n",
       "1692  0      0.001424\n",
       "1      0.001424\n",
       "2     -3.29015...   \n",
       "\n",
       "                                              others_cr  \\\n",
       "0     0      3.172441\n",
       "1     -0.278173\n",
       "2      3.17244...   \n",
       "1     0     -0.278173\n",
       "1      3.172441\n",
       "2     -0.18602...   \n",
       "2     0      3.172441\n",
       "1     -0.186023\n",
       "2     -0.21116...   \n",
       "3     0     -0.186023\n",
       "1     -0.211169\n",
       "2     -0.21116...   \n",
       "4     0     -0.211169\n",
       "1     -0.211169\n",
       "2     -0.25302...   \n",
       "...                                                 ...   \n",
       "1688  0     -0.150655\n",
       "1     -0.767155\n",
       "2     -0.76715...   \n",
       "1689  0     -0.767155\n",
       "1     -0.767155\n",
       "2     -0.06953...   \n",
       "1690  0     -0.767155\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1691  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.06953...   \n",
       "1692  0     -0.069537\n",
       "1     -0.069537\n",
       "2     -0.76715...   \n",
       "\n",
       "                                                 Return Target  \n",
       "0     0      0.260222\n",
       "1     -0.423366\n",
       "2     -1.10695...    0.0  \n",
       "1     0     -0.423366\n",
       "1     -1.106955\n",
       "2     -1.79054...    0.0  \n",
       "2     0     -1.106955\n",
       "1     -1.790544\n",
       "2     -2.47413...    0.0  \n",
       "3     0     -1.790544\n",
       "1     -2.474132\n",
       "2      0.26022...    0.0  \n",
       "4     0     -2.474132\n",
       "1      0.260222\n",
       "2      0.26022...    1.0  \n",
       "...                                                 ...    ...  \n",
       "1688  0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...    0.0  \n",
       "1689  0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...    0.0  \n",
       "1690  0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...    0.0  \n",
       "1691  0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...    0.0  \n",
       "1692  0      0.260222\n",
       "1      0.260222\n",
       "2      0.26022...    0.0  \n",
       "\n",
       "[1693 rows x 94 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d68e13-2f16-4e0c-a4af-11af2adc5ff6",
   "metadata": {},
   "source": [
    "**Define X and y in appropiate data format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588155e-56d2-47a7-831f-9e3727509146",
   "metadata": {},
   "source": [
    "First, set the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e790c5a-0473-4f3d-9c7b-8853494c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# if we do it on a rolling basis, we need to separate between train and test batch size\n",
    "if evaluation_metric == \"rolling\":\n",
    "    train_batch_size = batch_size\n",
    "    test_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e395c-88ad-46db-aa3e-a5410335c870",
   "metadata": {},
   "source": [
    "Now apply SMOTE techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c42871-ce0f-4486-8a7c-113d7bbc4f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size = 200\n",
    "transformation = None\n",
    "\n",
    "if model_type == \"gru\":\n",
    "    from _12_nn_models.gru import apply_smote, convert_to_tensor, reshape_remove_characters\n",
    "    \n",
    "    if transformation == \"smote\":\n",
    "        X_resampled, y_resampled = apply_smote(structured_df, device) # balance data\n",
    "\n",
    "    else:\n",
    "        X_resampled, y_resampled = reshape_remove_characters(structured_df) # balance data\n",
    "        \n",
    "    train_size = X_resampled.shape[0] - test_size\n",
    "    if evaluation_metric != \"rolling\":\n",
    "        trainloader, testloader = convert_to_tensor(X_resampled, y_resampled, \n",
    "                                                device, train_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fde710-4f79-4e3e-8a3c-e25e968167ac",
   "metadata": {},
   "source": [
    "**Choose model hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df3ffd2-b12c-4015-9520-d64c972ccc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "\n",
    "if model_type == \"gru\":\n",
    "    from _12_nn_models.gru import GRU3DClassifier\n",
    "    \n",
    "    # parameters for GRU\n",
    "    input_size = X_resampled.shape[2]\n",
    "    hidden_size = 64  \n",
    "    output_size = 2  \n",
    "    num_layers = 2\n",
    "    dropout = 0.2\n",
    "    \n",
    "    model = GRU3DClassifier(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "# choose optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba3e5a-b871-4adf-b9d8-a31ed8b428a0",
   "metadata": {},
   "source": [
    "**Train model and test model**\n",
    "\n",
    "Training can be done either on a rolling basis or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0736a113-2424-4b24-91a5-b36e68675c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing step 1493/1693...\n",
      "Processing step 1494/1693...\n",
      "Processing step 1495/1693...\n",
      "Processing step 1496/1693...\n",
      "Processing step 1497/1693...\n",
      "Processing step 1498/1693...\n",
      "Processing step 1499/1693...\n",
      "Processing step 1500/1693...\n",
      "Processing step 1501/1693...\n",
      "Processing step 1502/1693...\n",
      "Processing step 1503/1693...\n",
      "Processing step 1504/1693...\n",
      "Processing step 1505/1693...\n",
      "Processing step 1506/1693...\n",
      "Processing step 1507/1693...\n",
      "Processing step 1508/1693...\n",
      "Processing step 1509/1693...\n",
      "Processing step 1510/1693...\n",
      "Processing step 1511/1693...\n",
      "Processing step 1512/1693...\n",
      "Processing step 1513/1693...\n",
      "Processing step 1514/1693...\n",
      "Processing step 1515/1693...\n",
      "Processing step 1516/1693...\n",
      "Processing step 1517/1693...\n",
      "Processing step 1518/1693...\n",
      "Processing step 1519/1693...\n",
      "Processing step 1520/1693...\n",
      "Processing step 1521/1693...\n",
      "Processing step 1522/1693...\n",
      "Processing step 1523/1693...\n",
      "Processing step 1524/1693...\n",
      "Processing step 1525/1693...\n",
      "Processing step 1526/1693...\n",
      "Processing step 1527/1693...\n",
      "Processing step 1528/1693...\n",
      "Processing step 1529/1693...\n",
      "Processing step 1530/1693...\n",
      "Processing step 1531/1693...\n",
      "Processing step 1532/1693...\n",
      "Processing step 1533/1693...\n",
      "Processing step 1534/1693...\n",
      "Processing step 1535/1693...\n",
      "Processing step 1536/1693...\n",
      "Processing step 1537/1693...\n",
      "Processing step 1538/1693...\n",
      "Processing step 1539/1693...\n",
      "Processing step 1540/1693...\n",
      "Processing step 1541/1693...\n",
      "Processing step 1542/1693...\n",
      "Processing step 1543/1693...\n",
      "Processing step 1544/1693...\n",
      "Processing step 1545/1693...\n",
      "Processing step 1546/1693...\n",
      "Processing step 1547/1693...\n",
      "Processing step 1548/1693...\n",
      "Processing step 1549/1693...\n",
      "Processing step 1550/1693...\n",
      "Processing step 1551/1693...\n",
      "Processing step 1552/1693...\n",
      "Processing step 1553/1693...\n",
      "Processing step 1554/1693...\n",
      "Processing step 1555/1693...\n",
      "Processing step 1556/1693...\n",
      "Processing step 1557/1693...\n",
      "Processing step 1558/1693...\n",
      "Processing step 1559/1693...\n",
      "Processing step 1560/1693...\n",
      "Processing step 1561/1693...\n",
      "Processing step 1562/1693...\n",
      "Processing step 1563/1693...\n",
      "Processing step 1564/1693...\n",
      "Processing step 1565/1693...\n",
      "Processing step 1566/1693...\n",
      "Processing step 1567/1693...\n",
      "Processing step 1568/1693...\n",
      "Processing step 1569/1693...\n",
      "Processing step 1570/1693...\n",
      "Processing step 1571/1693...\n",
      "Processing step 1572/1693...\n",
      "Processing step 1573/1693...\n",
      "Processing step 1574/1693...\n",
      "Processing step 1575/1693...\n",
      "Processing step 1576/1693...\n",
      "Processing step 1577/1693...\n",
      "Processing step 1578/1693...\n",
      "Processing step 1579/1693...\n",
      "Processing step 1580/1693...\n",
      "Processing step 1581/1693...\n",
      "Processing step 1582/1693...\n",
      "Processing step 1583/1693...\n",
      "Processing step 1584/1693...\n",
      "Processing step 1585/1693...\n",
      "Processing step 1586/1693...\n",
      "Processing step 1587/1693...\n",
      "Processing step 1588/1693...\n",
      "Processing step 1589/1693...\n",
      "Processing step 1590/1693...\n",
      "Processing step 1591/1693...\n",
      "Processing step 1592/1693...\n",
      "Processing step 1593/1693...\n",
      "Processing step 1594/1693...\n",
      "Processing step 1595/1693...\n",
      "Processing step 1596/1693...\n",
      "Processing step 1597/1693...\n",
      "Processing step 1598/1693...\n",
      "Processing step 1599/1693...\n",
      "Processing step 1600/1693...\n",
      "Processing step 1601/1693...\n",
      "Processing step 1602/1693...\n",
      "Processing step 1603/1693...\n",
      "Processing step 1604/1693...\n",
      "Processing step 1605/1693...\n",
      "Processing step 1606/1693...\n",
      "Processing step 1607/1693...\n",
      "Processing step 1608/1693...\n",
      "Processing step 1609/1693...\n",
      "Processing step 1610/1693...\n",
      "Processing step 1611/1693...\n",
      "Processing step 1612/1693...\n",
      "Processing step 1613/1693...\n",
      "Processing step 1614/1693...\n",
      "Processing step 1615/1693...\n",
      "Processing step 1616/1693...\n",
      "Processing step 1617/1693...\n",
      "Processing step 1618/1693...\n",
      "Processing step 1619/1693...\n",
      "Processing step 1620/1693...\n",
      "Processing step 1621/1693...\n",
      "Processing step 1622/1693...\n",
      "Processing step 1623/1693...\n",
      "Processing step 1624/1693...\n",
      "Processing step 1625/1693...\n",
      "Processing step 1626/1693...\n",
      "Processing step 1627/1693...\n",
      "Processing step 1628/1693...\n",
      "Processing step 1629/1693...\n",
      "Processing step 1630/1693...\n",
      "Processing step 1631/1693...\n",
      "Processing step 1632/1693...\n",
      "Processing step 1633/1693...\n",
      "Processing step 1634/1693...\n",
      "Processing step 1635/1693...\n",
      "Processing step 1636/1693...\n",
      "Processing step 1637/1693...\n",
      "Processing step 1638/1693...\n",
      "Processing step 1639/1693...\n",
      "Processing step 1640/1693...\n",
      "Processing step 1641/1693...\n",
      "Processing step 1642/1693...\n",
      "Processing step 1643/1693...\n",
      "Processing step 1644/1693...\n",
      "Processing step 1645/1693...\n",
      "Processing step 1646/1693...\n",
      "Processing step 1647/1693...\n",
      "Processing step 1648/1693...\n",
      "Processing step 1649/1693...\n",
      "Processing step 1650/1693...\n",
      "Processing step 1651/1693...\n",
      "Processing step 1652/1693...\n",
      "Processing step 1653/1693...\n",
      "Processing step 1654/1693...\n",
      "Processing step 1655/1693...\n",
      "Processing step 1656/1693...\n",
      "Processing step 1657/1693...\n",
      "Processing step 1658/1693...\n",
      "Processing step 1659/1693...\n",
      "Processing step 1660/1693...\n",
      "Processing step 1661/1693...\n",
      "Processing step 1662/1693...\n",
      "Processing step 1663/1693...\n",
      "Processing step 1664/1693...\n",
      "Processing step 1665/1693...\n",
      "Processing step 1666/1693...\n",
      "Processing step 1667/1693...\n",
      "Processing step 1668/1693...\n",
      "Processing step 1669/1693...\n",
      "Processing step 1670/1693...\n",
      "Processing step 1671/1693...\n",
      "Processing step 1672/1693...\n",
      "Processing step 1673/1693...\n",
      "Processing step 1674/1693...\n",
      "Processing step 1675/1693...\n",
      "Processing step 1676/1693...\n",
      "Processing step 1677/1693...\n",
      "Processing step 1678/1693...\n",
      "Processing step 1679/1693...\n",
      "Processing step 1680/1693...\n",
      "Processing step 1681/1693...\n",
      "Processing step 1682/1693...\n",
      "Processing step 1683/1693...\n",
      "Processing step 1684/1693...\n",
      "Processing step 1685/1693...\n",
      "Processing step 1686/1693...\n",
      "Processing step 1687/1693...\n",
      "Processing step 1688/1693...\n",
      "Processing step 1689/1693...\n",
      "Processing step 1690/1693...\n",
      "Processing step 1691/1693...\n",
      "Processing step 1692/1693...\n",
      "Rolling Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "if evaluation_metric != \"rolling\":\n",
    "    \n",
    "    if model_type == \"gru\":\n",
    "        \n",
    "        from _12_nn_models.gru import train_model, evaluate_model\n",
    "        train_accuracy = train_model(model, optimizer, num_epochs, trainloader, criterion, device)\n",
    "        test_accuracy = evaluate_model(model, testloader, criterion, device)\n",
    "\n",
    "elif evaluation_metric == \"rolling\":\n",
    "    if model_type == \"gru\":\n",
    "        from _12_nn_models.gru import evaluate_rolling_model\n",
    "        train_accuracy = \"Not computed\"\n",
    "        rolling_predictions, rolling_targets, test_accuracy = evaluate_rolling_model(model, X_resampled, y_resampled, criterion, \n",
    "                                               optimizer, device, train_size, train_batch_size, test_batch_size, num_epochs)\n",
    "        \n",
    "end_time = time.time()    \n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c4685f-5ec4-4c93-8d28-5cc7d74eba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot realized (actual) values\n",
    "plt.plot(range(len(rolling_targets)), rolling_targets, label=\"Realized (Actual)\", color=\"blue\", marker=\"o\", linestyle=\"-\")\n",
    "\n",
    "# Plot predicted values\n",
    "plt.plot(range(len(rolling_predictions)), rolling_predictions, label=\"Predicted\", color=\"red\", marker=\"x\", linestyle=\"--\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(f\"Realized vs Predicted Values (Test Accuracy: {test_accuracy:.4f})\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dad1b-3596-461a-9573-93a4ca26caf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "for lr in np.arange(0.01, 0.11, 0.01):\n",
    "    learning_rate = lr\n",
    "    if model_type == \"gru\":\n",
    "        from _12_nn_models.gru import train_model, evaluate_model\n",
    "        start_time = time.time()\n",
    "        train_accuracy = train_model(model, optimizer, num_epochs, trainloader, criterion, device)\n",
    "        test_accuracy = evaluate_model(model, testloader, criterion, device)\n",
    "\n",
    "        end_time = time.time()    \n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "    store_results(\n",
    "        results_filepath,\n",
    "        horizontal_filename,\n",
    "        stock,\n",
    "        data_type,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        scaling_method,\n",
    "        processing_method,\n",
    "        window_size,\n",
    "        model_type,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        execution_time,\n",
    "        num_layers,\n",
    "        str(criterion),\n",
    "        str(optimizer).split('\\n')[0].strip(' ('),\n",
    "        dropout,  # Example of additional model parameter\n",
    "        train_accuracy,\n",
    "        test_accuracy\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d6eaf-6292-47e6-9715-099dfb6723be",
   "metadata": {},
   "source": [
    "## **3. Store results**\n",
    "\n",
    "This part of the code structures the process of saving results in a dataframe. At the moment, standardized for:\n",
    "\n",
    "    - Objective: generate columns appropiately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f806a2bf-98b3-4f9a-a6fa-f7642f661ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(project_dir, \"results\")\n",
    "\n",
    "if evaluation_metric == \"rolling\":\n",
    "    results_filepath = os.path.join(results_dir, \"results_rolling.csv\")\n",
    "else:\n",
    "    results_filepath = os.path.join(results_dir, \"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caba00ee-44bf-4045-a7bf-fe1a2c0e439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(\n",
    "    output_filepath,  # Path to save or update the CSV file\n",
    "    data_filepath,    # Path to the data file\n",
    "    stock,            # Stock(s)\n",
    "    data_type,        # Type of data (Technical/Economic/Options)\n",
    "    start_date,       # Start date\n",
    "    end_date,         # End date\n",
    "    scaling_method,   # Scaling method (standard/minmax/none)\n",
    "    processing_method,  # Processing method (PCA/none)\n",
    "    window_size,      # Window size\n",
    "    model_name,       # Model name\n",
    "    batch_size,\n",
    "    learning_rate,    # Learning rate\n",
    "    num_epochs,       # Number of epochs\n",
    "    execution_time,   # Execution time (seconds)\n",
    "    num_layers,       # Number of layers\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dropout_rate,\n",
    "    train_accuracy,\n",
    "    test_accuracy,\n",
    "    **kwargs          # Additional model parameters (optional)\n",
    "):\n",
    "    \"\"\"\n",
    "    Appends results with data and model parameters to a CSV file.\n",
    "\n",
    "    \"\"\"\n",
    "    # Organize all data-related columns\n",
    "    data_params = {\n",
    "        \"Data Filepath\": data_filepath,\n",
    "        \"Stock(s)\": stock,\n",
    "        \"Data Type\": data_type,\n",
    "        \"Start-End Date (Values)\": f\"{start_date} - {end_date}\",\n",
    "        \"Scaling Method\": scaling_method,\n",
    "        \"Processing Method\": processing_method,\n",
    "        \"Window Size\": window_size\n",
    "    }\n",
    "\n",
    "    # Organize all model-related columns\n",
    "    model_params = {\n",
    "        \"Model\": model_name,\n",
    "        \"Date Performed\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Learning Rate\": learning_rate,\n",
    "        \"Num Epochs\": num_epochs,\n",
    "        \"Execution Time (s)\": execution_time,\n",
    "        \"Number of Layers\": num_layers,\n",
    "        \"Criterion\" : criterion,\n",
    "        \"Optimizer\" : optimizer,\n",
    "        \"Dropout Rate\" : dropout_rate\n",
    "    }\n",
    "    \n",
    "    result_params = {\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    }\n",
    "\n",
    "    # Merge additional model parameters passed as kwargs\n",
    "    model_params.update(kwargs)\n",
    "\n",
    "    # Combine data and model parameters into one row\n",
    "    result_row = {**data_params, **model_params, **result_params}\n",
    "\n",
    "    # Load existing results or create a new DataFrame\n",
    "    if os.path.exists(output_filepath):\n",
    "        results_df = pd.read_csv(output_filepath)\n",
    "    else:\n",
    "        results_df = pd.DataFrame(columns=result_row.keys())\n",
    "\n",
    "    # Append the new row using pd.concat\n",
    "    new_row_df = pd.DataFrame([result_row])  # Create a DataFrame from the new row\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "    # Save back to the CSV\n",
    "    results_df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Results stored successfully in: {output_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a31235e0-dd18-4bd9-9b1f-3f2c208e1987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results stored successfully in: /home/jupyter-tfg2425paula/prediction_project_v2/results/results_rolling.csv\n"
     ]
    }
   ],
   "source": [
    "store_results(\n",
    "        results_filepath,\n",
    "        horizontal_filename,\n",
    "        stock,\n",
    "        data_type,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        scaling_method,\n",
    "        processing_method,\n",
    "        window_size,\n",
    "        model_type,\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        num_epochs,\n",
    "        execution_time,\n",
    "        num_layers,\n",
    "        str(criterion),\n",
    "        str(optimizer).split('\\n')[0].strip(' ('),\n",
    "        dropout,  # Example of additional model parameter\n",
    "        train_accuracy,\n",
    "        test_accuracy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e5b8b-1dab-4626-892d-418c00e2b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
